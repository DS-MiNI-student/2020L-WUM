{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAR OF BOOSTING DECISION TREES\n",
    "In this notebook we will se amazing fight between superb machine learning algorythms.\n",
    "To do this we will need some tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import random\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>1004.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.4</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.4</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     17.9     35.2       0.0         12.0      12.3           48.0   \n",
       "1     18.4     28.9       0.0         14.8      13.0           37.0   \n",
       "2     19.4     37.6       0.0         10.8      10.6           46.0   \n",
       "3     21.9     38.4       0.0         11.4      12.2           31.0   \n",
       "4     24.2     41.0       0.0         11.2       8.4           35.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "0           6.0          20.0         20.0         13.0       1006.3   \n",
       "1          19.0          19.0         30.0          8.0       1012.9   \n",
       "2          30.0          15.0         42.0         22.0       1012.3   \n",
       "3           6.0           6.0         37.0         22.0       1012.7   \n",
       "4          17.0          13.0         19.0         15.0       1010.7   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  \n",
       "0       1004.4       2.0       5.0     26.6     33.4          0             0  \n",
       "1       1012.1       1.0       1.0     20.3     27.0          0             0  \n",
       "2       1009.2       1.0       6.0     28.7     34.9          0             0  \n",
       "3       1009.1       1.0       5.0     29.1     35.6          0             0  \n",
       "4       1007.4       1.0       6.0     33.6     37.6          0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../australia.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make sense to conver this through logarythmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.RainTomorrow, np.log(data.Rainfall+1))\n",
    "data.Rainfall = np.log(data.Rainfall + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.RainTomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56420, 18)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"RainTomorrow\", axis =1), data.RainTomorrow, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22025877348457992"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.RainTomorrow.sum()/data.RainTomorrow.size            # 78 percent of data is one class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our classifiers we have to establish level playing field. It will be this function. Gets 5 fold crossvalidation of model on training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def model_auc(X,y, model, n_iter = 5): \n",
    "    \"\"\"\n",
    "    5 fold crossvalidation\n",
    "    repeated n_iter times\n",
    "    \n",
    "    returns mean auc for predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    out = []\n",
    "    for i in range(n_iter):\n",
    "        kf = KFold(n_splits=5, shuffle= True)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print('started training')\n",
    "            X_train_, X_cv = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train_, y_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            model.fit(X_train_, y_train_)\n",
    "            \n",
    "            y_prob_ = model.predict_proba(X_cv)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_cv, y_prob_)\n",
    "            out.append(auc(fpr,tpr))\n",
    "            \n",
    "            print('ended training')\n",
    "    return np.array(out).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contestant 1 - LightGBM\n",
    "Powerful model. Featherweight. It is said that it grows leaf-wise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base \n",
    "How deafult parameters of model are performing. We will see here and in upcoming models how tuning changes `auc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model_base = LGBMClassifier(metric = \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.893259889258849"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, lgb_model, n_iter = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is quite good but I bet we could do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hiperparameter tuning i will do it with BayesSearchCV, instead of grid, which is very  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(metric = \"auc\", objective=\"binary\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,random_state=22,shuffle = True) # 5 fold crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgb = {\n",
    "                  \"boosting_type\": [\"gbdt\",'dart'], \n",
    "                  \"learning_rate\": [0.001,0.01,0.07,0.1,0.5,1], \n",
    "                  \"num_leaves\" : [5,15,25,50,100], \n",
    "                  \"colsample_bytree\" : [0.1,0.3, 0.5,0.7,1],\n",
    "                  \"max_depth\" : [-1, 5, 10,15, 100], \n",
    "                  'min_child_samples' : [0,3,6,9,15,25,40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv = RandomizedSearchCV(lgb_model,\n",
    "                        param_grid_lgb,\n",
    "                        cv =skf,\n",
    "                        n_iter=100,\n",
    "                        n_jobs = -1\n",
    "                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=22, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='auc', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=3...\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'dart'],\n",
       "                                        'colsample_bytree': [0.1, 0.3, 0.5, 0.7,\n",
       "                                                             1],\n",
       "                                        'learning_rate': [0.001, 0.01, 0.07,\n",
       "                                                          0.1, 0.5, 1],\n",
       "                                        'max_depth': [-1, 5, 10, 15, 100],\n",
       "                                        'min_child_samples': [0, 3, 6, 9, 15,\n",
       "                                                              25, 40],\n",
       "                                        'num_leaves': [5, 15, 25, 50, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 50,\n",
       "  'min_child_samples': 25,\n",
       "  'max_depth': 15,\n",
       "  'learning_rate': 0.1,\n",
       "  'colsample_bytree': 1,\n",
       "  'boosting_type': 'gbdt'},\n",
       " 0.8592696802518158)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.best_params_ , searchcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(learning_rate = 0.1,\n",
    "                           colsample_bytree = 1,\n",
    "                           boosting_type = \"gbdt\",\n",
    "                           n_estimators = 200,\n",
    "                           max_depth = 15, \n",
    "                          num_leaves = 50, \n",
    "                          metric = \"auc\", \n",
    "                          num_iterations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakwisn/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8939860080046683"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, lgb_model, n_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than base by 0.0007. Very marginal difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contestant 2 - Xgboost \n",
    "Another powerful contestant. Thinks that leaf-wise grow is stupid and prefers conservative level-wise growth. Called Extreme by some."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(metric = \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.891290408877525"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, xgb_model,n_iter =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By dafult little worse than LGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\"max_depth\":np.arange(4,100),\n",
    "                  \"learning_rate\":np.arange(0.001,1,0.1),\n",
    "                  \"booster\" : [\"dart\",\"gbtree\"],\n",
    "                  \"colsample_bylevel\" : np.arange(0.1,1,0.1),\n",
    "                  \"reg_alpha\":np.arange(0,10,0.1),\n",
    "                  \"reg_lambda\":np.arange(0,10,0.1)\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv = RandomizedSearchCV(xgb_model,\n",
    "                        param_grid_xgb,\n",
    "                        cv =skf,\n",
    "                        n_iter=50,\n",
    "                        n_jobs = -1\n",
    "                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=22, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster=None,\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.300000012,\n",
       "                                           max_delta_step=0, max_depth=6,\n",
       "                                           metric='auc', min_chi...\n",
       "       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,\n",
       "       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1,\n",
       "       5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4,\n",
       "       6.5, 6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7,\n",
       "       7.8, 7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. ,\n",
       "       9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 8.8,\n",
       "  'reg_alpha': 4.1000000000000005,\n",
       "  'max_depth': 99,\n",
       "  'learning_rate': 0.101,\n",
       "  'colsample_bylevel': 0.4,\n",
       "  'booster': 'gbtree'},\n",
       " 0.8624821910971658)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.best_params_ , searchcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(metric = \"auc\",\n",
    "                         booster = 'gbtree',\n",
    "                         colsample_bylevel = 0.4,\n",
    "                         learning_rate = 0.1,\n",
    "                         max_depth = 99, \n",
    "                         reg_alpha = 4.1, \n",
    "                         reg_lambda = 8.8, \n",
    "                         n_iter = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8965226699273348"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, xgb_model,n_iter =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better! By 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contestant 3 - Catboost\n",
    "Russian cousin, the weird one. Likes categories, is big, fast and strong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(eval_metric='AUC', iterations = 100, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8933666263335297"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, cat_model,n_iter =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_cat = {\n",
    "                  \"max_depth\":np.arange(2,16),\n",
    "                  \"l2_leaf_reg\": [0.001, 0.1,0.5,1,5,10,100],\n",
    "                  \"use_best_model\": [True, False],\n",
    "                  \"num_trees\": [100,300,500,1000],\n",
    "                  \"min_data_in_leaf\": [1,3,5,8,14,25,50,80]\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv = RandomizedSearchCV(cat_model, param_grid_cat, cv = skf) # 5 fold crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'use_best_model': False,\n",
       "  'num_trees': 1000,\n",
       "  'min_data_in_leaf': 50,\n",
       "  'max_depth': 9,\n",
       "  'l2_leaf_reg': 1},\n",
       " 0.8639887407143018)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.best_params_ , searchcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(eval_metric='AUC',\n",
    "                               num_trees = 1000 ,\n",
    "                              l2_leaf_reg=1,\n",
    "                              max_depth=9,\n",
    "                              min_data_in_leaf=50,\n",
    "                              verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n",
      "started training\n",
      "ended training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8985058119211505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_auc(X_train, y_train, cat_model,n_iter =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better by 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of fight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well our models perform on `test` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let them fit to whole data, and then we will test them on test set, that they never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f9728de8a50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "cat_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_prob_lgb = lgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "y_prob_cat = cat_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------LGB------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.884     0.945     0.913      8816\n",
      "           1      0.740     0.556     0.635      2468\n",
      "\n",
      "    accuracy                          0.860     11284\n",
      "   macro avg      0.812     0.751     0.774     11284\n",
      "weighted avg      0.852     0.860     0.852     11284\n",
      "\n",
      "---------------XGB------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     0.948     0.915      8816\n",
      "           1      0.750     0.561     0.642      2468\n",
      "\n",
      "    accuracy                          0.863     11284\n",
      "   macro avg      0.818     0.754     0.779     11284\n",
      "weighted avg      0.856     0.863     0.856     11284\n",
      "\n",
      "---------------CAT------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.883     0.948     0.915      8816\n",
      "           1      0.749     0.553     0.636      2468\n",
      "\n",
      "    accuracy                          0.862     11284\n",
      "   macro avg      0.816     0.750     0.775     11284\n",
      "weighted avg      0.854     0.862     0.854     11284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------LGB------------\")\n",
    "lgb = classification_report(y_test,y_pred_lgb, digits = 3)\n",
    "print(lgb)\n",
    "print(\"---------------XGB------------\")\n",
    "xgb = classification_report(y_test,y_pred_xgb, digits = 3)\n",
    "print(xgb)\n",
    "print(\"---------------CAT------------\")\n",
    "cat = classification_report(y_test,y_pred_cat, digits = 3)\n",
    "print(cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see Models are very similar in terms of output. Judging on `acc` and `f1`\n",
    "score the winner is CAT and XGB has the second place. Lets see how well our `AUC` is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB's AUC : 0.8955586590021971 \n",
      "XGB's AUC : 0.8973239038641987 \n",
      "CAT's AUC : 0.8996378233034383 \n",
      "   \n"
     ]
    }
   ],
   "source": [
    "fpr_l, tpr_l, _ = roc_curve(y_test, y_prob_lgb)\n",
    "lgb_auc = auc(fpr_l,tpr_l)\n",
    "\n",
    "fpr_x, tpr_x, _ = roc_curve(y_test, y_prob_xgb)\n",
    "xgb_auc = auc(fpr_x,tpr_x)\n",
    "\n",
    "fpr_c,tpr_c, _  = roc_curve(y_test, y_prob_cat) \n",
    "cat_auc = auc(fpr_c,tpr_c)\n",
    "\n",
    "print(f'LGB\\'s AUC : {lgb_auc} \\nXGB\\'s AUC : {xgb_auc} \\nCAT\\'s AUC : {cat_auc} \\n   ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the winner is CAT!!!** \n",
    "\n",
    "...but it is really sad we didn't surpass 0.9 `auc` :(\n",
    "\n",
    "So let's try just another thing.\n",
    "So what if we use **All** our models? Let's use mean of their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_new, tpr_new, _ = roc_curve(y_test, np.array(y_prob_lgb + y_prob_xgb + y_prob_cat )/3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9002051118196767"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr_new,tpr_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we've got another winner! Team work is worth the struggle after all. Let's bury the hatchet and declare all models a winer. That is right there are no losers here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap-up\n",
    "All models were really good even without tuning. Some of them have parameters that fit to the data and control overfitting. I was not surprised that even with long tuning we had only marginally improved `auc`. At the end i did something which is called model ensamble. It basically is aggregating models predictions. In my case it was mean of predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://www.dropbox.com/s/360xhh2d9lnaek3/allegro-api-transactions.csv?dl=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp</th>\n",
       "      <th>date</th>\n",
       "      <th>item_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>pay_option_on_delivery</th>\n",
       "      <th>pay_option_transfer</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>it_is_allegro_standard</th>\n",
       "      <th>it_quantity</th>\n",
       "      <th>it_is_brand_zone</th>\n",
       "      <th>it_seller_rating</th>\n",
       "      <th>it_location</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-03 21:21:08</td>\n",
       "      <td>4753602474</td>\n",
       "      <td>['Komputery', 'Dyski i napędy', 'Nośniki', 'No...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>radzioch666</td>\n",
       "      <td>59.99</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>50177</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Komputery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-03 15:35:26</td>\n",
       "      <td>4773181874</td>\n",
       "      <td>['Odzież, Obuwie, Dodatki', 'Bielizna damska',...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>InwestycjeNET</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1</td>\n",
       "      <td>9288</td>\n",
       "      <td>0</td>\n",
       "      <td>12428</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Odzież, Obuwie, Dodatki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-03 14:14:31</td>\n",
       "      <td>4781627074</td>\n",
       "      <td>['Dom i Ogród', 'Budownictwo i Akcesoria', 'Śc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>otostyl_com</td>\n",
       "      <td>109.90</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>7389</td>\n",
       "      <td>Leszno</td>\n",
       "      <td>Dom i Ogród</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-03 19:55:44</td>\n",
       "      <td>4783971474</td>\n",
       "      <td>['Książki i Komiksy', 'Poradniki i albumy', 'Z...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Matfel1</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "      <td>0</td>\n",
       "      <td>15006</td>\n",
       "      <td>Wola Krzysztoporska</td>\n",
       "      <td>Książki i Komiksy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-03 18:05:54</td>\n",
       "      <td>4787908274</td>\n",
       "      <td>['Odzież, Obuwie, Dodatki', 'Ślub i wesele', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PPHU_RICO</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>32975</td>\n",
       "      <td>BIAŁYSTOK</td>\n",
       "      <td>Odzież, Obuwie, Dodatki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lp                 date     item_id  \\\n",
       "0   0  2016-04-03 21:21:08  4753602474   \n",
       "1   1  2016-04-03 15:35:26  4773181874   \n",
       "2   2  2016-04-03 14:14:31  4781627074   \n",
       "3   3  2016-04-03 19:55:44  4783971474   \n",
       "4   4  2016-04-03 18:05:54  4787908274   \n",
       "\n",
       "                                          categories  pay_option_on_delivery  \\\n",
       "0  ['Komputery', 'Dyski i napędy', 'Nośniki', 'No...                       1   \n",
       "1  ['Odzież, Obuwie, Dodatki', 'Bielizna damska',...                       1   \n",
       "2  ['Dom i Ogród', 'Budownictwo i Akcesoria', 'Śc...                       1   \n",
       "3  ['Książki i Komiksy', 'Poradniki i albumy', 'Z...                       1   \n",
       "4  ['Odzież, Obuwie, Dodatki', 'Ślub i wesele', '...                       1   \n",
       "\n",
       "   pay_option_transfer         seller   price  it_is_allegro_standard  \\\n",
       "0                    1    radzioch666   59.99                       1   \n",
       "1                    1  InwestycjeNET    4.90                       1   \n",
       "2                    1    otostyl_com  109.90                       1   \n",
       "3                    1        Matfel1   18.50                       0   \n",
       "4                    1      PPHU_RICO   19.90                       1   \n",
       "\n",
       "   it_quantity  it_is_brand_zone  it_seller_rating          it_location  \\\n",
       "0          997                 0             50177             Warszawa   \n",
       "1         9288                 0             12428             Warszawa   \n",
       "2          895                 0              7389               Leszno   \n",
       "3          971                 0             15006  Wola Krzysztoporska   \n",
       "4          950                 0             32975            BIAŁYSTOK   \n",
       "\n",
       "             main_category  \n",
       "0                Komputery  \n",
       "1  Odzież, Obuwie, Dodatki  \n",
       "2              Dom i Ogród  \n",
       "3        Książki i Komiksy  \n",
       "4  Odzież, Obuwie, Dodatki  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ip, date and item_id won't tell our model much, additionally let's delete categories and leve only main category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pay_option_on_delivery</th>\n",
       "      <th>pay_option_transfer</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>it_is_allegro_standard</th>\n",
       "      <th>it_quantity</th>\n",
       "      <th>it_is_brand_zone</th>\n",
       "      <th>it_seller_rating</th>\n",
       "      <th>it_location</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>radzioch666</td>\n",
       "      <td>59.99</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>50177</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Komputery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>InwestycjeNET</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1</td>\n",
       "      <td>9288</td>\n",
       "      <td>0</td>\n",
       "      <td>12428</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Odzież, Obuwie, Dodatki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>otostyl_com</td>\n",
       "      <td>109.90</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>7389</td>\n",
       "      <td>Leszno</td>\n",
       "      <td>Dom i Ogród</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Matfel1</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "      <td>0</td>\n",
       "      <td>15006</td>\n",
       "      <td>Wola Krzysztoporska</td>\n",
       "      <td>Książki i Komiksy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PPHU_RICO</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>32975</td>\n",
       "      <td>BIAŁYSTOK</td>\n",
       "      <td>Odzież, Obuwie, Dodatki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pay_option_on_delivery  pay_option_transfer         seller   price  \\\n",
       "0                       1                    1    radzioch666   59.99   \n",
       "1                       1                    1  InwestycjeNET    4.90   \n",
       "2                       1                    1    otostyl_com  109.90   \n",
       "3                       1                    1        Matfel1   18.50   \n",
       "4                       1                    1      PPHU_RICO   19.90   \n",
       "\n",
       "   it_is_allegro_standard  it_quantity  it_is_brand_zone  it_seller_rating  \\\n",
       "0                       1          997                 0             50177   \n",
       "1                       1         9288                 0             12428   \n",
       "2                       1          895                 0              7389   \n",
       "3                       0          971                 0             15006   \n",
       "4                       1          950                 0             32975   \n",
       "\n",
       "           it_location            main_category  \n",
       "0             Warszawa                Komputery  \n",
       "1             Warszawa  Odzież, Obuwie, Dodatki  \n",
       "2               Leszno              Dom i Ogród  \n",
       "3  Wola Krzysztoporska        Książki i Komiksy  \n",
       "4            BIAŁYSTOK  Odzież, Obuwie, Dodatki  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pay_option_on_delivery      int64\n",
       "pay_option_transfer         int64\n",
       "seller                     object\n",
       "price                     float64\n",
       "it_is_allegro_standard      int64\n",
       "it_quantity                 int64\n",
       "it_is_brand_zone            int64\n",
       "it_seller_rating            int64\n",
       "it_location                object\n",
       "main_category              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task \n",
    "We will try 3 diffrent encoders on data, and then we will take a look at the magic of catboost. Of course we will do it on chunk of data from obvious reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking individual categories winner from previous task.\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = extra_data.sample(frac = 1) # shuffle \n",
    "extra_data = extra_data.iloc[0:20000,:] # take first 20.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing encoders that don't need target, and doing it on deafult regressor settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"it_location\",\"main_category\", \"seller\"]\n",
    "oe = ce.one_hot.OrdinalEncoder(cols = cols) # ordinal \n",
    "be = ce.basen.BaseNEncoder(cols = cols , base= 10) # base n\n",
    "oh = ce.one_hot.OneHotEncoder(cols = cols) # hashing\n",
    "\n",
    "encoders = [oh, be, oe]\n",
    "\n",
    "model_regression = CatBoostRegressor(verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = []\n",
    "rmse = []\n",
    "\n",
    "for i in range(len(encoders)): \n",
    "    \n",
    "    encoder = encoders[i]\n",
    "    X_transformed =  encoder.fit_transform(extra_data.drop(\"price\", axis =1))\n",
    "    \n",
    "    random.seed(42)\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(X_transformed,extra_data.price,test_size = 0.2)\n",
    "    \n",
    "\n",
    "    model_regression.fit(X2_train, y2_train)\n",
    "    y_enc_pred = model_regression.predict(X2_test)\n",
    "    \n",
    "    r2.append(r2_score(y2_test, y_enc_pred))\n",
    "    rmse.append(mean_squared_error(y2_test, y_enc_pred, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08408948700708996, 0.05940363934444093, 0.0868072233698276]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2  # preety terrible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[165.22537109903502, 231.28361780736512, 198.13421243387847]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: \n",
      " One-Hot: 0.08408948700708996, BaseN: 0.05940363934444093, Ordinal: 0.0868072233698276 \n",
      "RMSE: \n",
      " One-Hot: 165.22537109903502, BaseN: 231.28361780736512, Ordinal: 198.13421243387847\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: \\n One-Hot: {r2[0]}, BaseN: {r2[1]}, Ordinal: {r2[2]} \\nRMSE: \\n One-Hot: {rmse[0]}, BaseN: {rmse[1]}, Ordinal: {rmse[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall those encoders were really bad. Really close to random guesses in terms of `R2`. One hot encoder was better in `RMSE` and second after Ordinal in `R2` metrics. Target encoding would be much better here.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
