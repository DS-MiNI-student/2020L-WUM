{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Marcin Łukaszyk WUM PD 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodowanie zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pierwszej części zadaniem jest zakodowanie zmiennych kategorycznych.Najpierw użyjemy Target Encoding a potem użyjemy algorytmu One Hot jak i Polynomial Coding oraz Helmert Coding.\n",
    "Będziemy pracować na zborze danych \"Allegro\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sposoby działania algorytmów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot:\n",
    "\n",
    "Ten algorytm dla każdej zmiennej przyporządkowuje jedną kolumne dla jednej zmiennej konkretnego typy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Coding:\n",
    "\n",
    "Ten algorytm \"szuka\" linowych,kwadratowych i sześćściennych zależnośći pomiędzy zmiennymi kategorycznymi i na tej podstawie koduje te zmienne \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helmert Coding:\n",
    "Ten algorytm koduje zmienne na podstawie średnich tych zmiennych które jeszcze nie zostały zakodowane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie Danych I Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('allegro-api-transactions.csv')\n",
    "pd.set_option('display.max_columns', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy są braki danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lp                        0.0\n",
       "date                      0.0\n",
       "item_id                   0.0\n",
       "categories                0.0\n",
       "pay_option_on_delivery    0.0\n",
       "pay_option_transfer       0.0\n",
       "seller                    0.0\n",
       "price                     0.0\n",
       "it_is_allegro_standard    0.0\n",
       "it_quantity               0.0\n",
       "it_is_brand_zone          0.0\n",
       "it_seller_rating          0.0\n",
       "it_location               0.0\n",
       "main_category             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_ratio_cols = data.isna().mean(axis=0)\n",
    "na_ratio_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie ma braków danych. To dobrze :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                it_location   price  target_encoded\n",
      "0                  Warszawa   59.99       85.423398\n",
      "1                  Warszawa    4.90       85.423398\n",
      "2                    Leszno  109.90       61.990914\n",
      "3       Wola Krzysztoporska   18.50       35.433365\n",
      "4                 BIAŁYSTOK   19.90      117.191956\n",
      "...                     ...     ...             ...\n",
      "420015              Kraśnik  180.00       24.306929\n",
      "420016          Dzierżoniów   14.99       66.785334\n",
      "420017              Supraśl    5.99       18.682800\n",
      "420018               Poznań  200.00      106.203076\n",
      "420019                Pszów  500.00       78.136792\n",
      "\n",
      "[420020 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "target_v = data['price'].to_numpy()\n",
    "values = data['it_location'].to_numpy()\n",
    "values_main = data['main_category'].to_numpy()\n",
    "\n",
    "te = ce.target_encoder.TargetEncoder(data)\n",
    "\n",
    "data_tmp = data.copy()\n",
    "encoded = te.fit_transform(data['it_location'], data['price'])\n",
    "data_tmp['target_encoded'] = encoded\n",
    "\n",
    "print(data_tmp[['it_location', 'price', 'target_encoded']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   main_category_1  main_category_2  main_category_3  main_category_4  ...  \\\n",
      "0                1                0                0                0  ...   \n",
      "1                0                1                0                0  ...   \n",
      "2                0                0                1                0  ...   \n",
      "3                0                0                0                1  ...   \n",
      "4                0                1                0                0  ...   \n",
      "5                0                1                0                0  ...   \n",
      "6                0                1                0                0  ...   \n",
      "7                0                0                0                0  ...   \n",
      "\n",
      "   main_category_24  main_category_25  main_category_26  main_category_27  \n",
      "0                 0                 0                 0                 0  \n",
      "1                 0                 0                 0                 0  \n",
      "2                 0                 0                 0                 0  \n",
      "3                 0                 0                 0                 0  \n",
      "4                 0                 0                 0                 0  \n",
      "5                 0                 0                 0                 0  \n",
      "6                 0                 0                 0                 0  \n",
      "7                 0                 0                 0                 0  \n",
      "\n",
      "[8 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "te = ce.one_hot.OneHotEncoder(data)\n",
    "\n",
    "data_tmp = data.copy()\n",
    "encoded = te.fit_transform(data['main_category'])\n",
    "encoded = encoded.head(8)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każda zmienna ma jedynke w osobnym miejscu.Widać że dla rzędu 1 oraz 4 jedynka występuje w tej samej kolumnie co oznacza żę kodują one taką samą zmienną."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   intercept  main_category_0  main_category_1  main_category_2  ...  \\\n",
      "0          1        -0.321208         0.385019        -0.407465  ...   \n",
      "1          1        -0.296500         0.296168        -0.219404  ...   \n",
      "2          1        -0.271791         0.214426        -0.068956  ...   \n",
      "3          1        -0.247083         0.139791         0.047015  ...   \n",
      "4          1        -0.296500         0.296168        -0.219404  ...   \n",
      "5          1        -0.296500         0.296168        -0.219404  ...   \n",
      "6          1        -0.296500         0.296168        -0.219404  ...   \n",
      "7          1        -0.222375         0.072265         0.131643  ...   \n",
      "\n",
      "   main_category_22  main_category_23  main_category_24  main_category_25  \n",
      "0         -0.000006          0.000002     -3.206859e-07      4.490496e-08  \n",
      "1          0.000131         -0.000035      7.696462e-06     -1.167529e-06  \n",
      "2         -0.001243          0.000370     -8.818862e-05      1.459412e-05  \n",
      "3          0.007334         -0.002432      6.413718e-04     -1.167529e-04  \n",
      "4          0.000131         -0.000035      7.696462e-06     -1.167529e-06  \n",
      "5          0.000131         -0.000035      7.696462e-06     -1.167529e-06  \n",
      "6          0.000131         -0.000035      7.696462e-06     -1.167529e-06  \n",
      "7         -0.029956          0.011235     -3.319099e-03      6.713295e-04  \n",
      "\n",
      "[8 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "te = ce.polynomial.PolynomialEncoder(data)\n",
    "\n",
    "data_tmp = data.copy()\n",
    "encoded = te.fit_transform(data['main_category'])\n",
    "print(encoded.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmert Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   intercept  main_category_0  main_category_1  main_category_2  ...  \\\n",
      "0          1             -1.0             -1.0             -1.0  ...   \n",
      "1          1              1.0             -1.0             -1.0  ...   \n",
      "2          1              0.0              2.0             -1.0  ...   \n",
      "3          1              0.0              0.0              3.0  ...   \n",
      "4          1              1.0             -1.0             -1.0  ...   \n",
      "5          1              1.0             -1.0             -1.0  ...   \n",
      "6          1              1.0             -1.0             -1.0  ...   \n",
      "7          1              0.0              0.0              0.0  ...   \n",
      "\n",
      "   main_category_22  main_category_23  main_category_24  main_category_25  \n",
      "0              -1.0              -1.0              -1.0              -1.0  \n",
      "1              -1.0              -1.0              -1.0              -1.0  \n",
      "2              -1.0              -1.0              -1.0              -1.0  \n",
      "3              -1.0              -1.0              -1.0              -1.0  \n",
      "4              -1.0              -1.0              -1.0              -1.0  \n",
      "5              -1.0              -1.0              -1.0              -1.0  \n",
      "6              -1.0              -1.0              -1.0              -1.0  \n",
      "7              -1.0              -1.0              -1.0              -1.0  \n",
      "\n",
      "[8 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "te = ce.helmert.HelmertEncoder(data)\n",
    "\n",
    "data_tmp = data.copy()\n",
    "encoded = te.fit_transform(data['main_category'])\n",
    "print(encoded.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot a Target Encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedną z zalet Target Encodingu jest nie zajmowanie dodatkowego miejsca gdzie przy One-Hot zajmujemy go proporcjonalnie do ilości rózny wartośći.Wadą natomiast jest możliwość data leak. Tzn że przez małą ilośći danych o konkretej zmiennej algorytm nie będzie działał poprawnie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uzupełnianie Braków Danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z powyższego zbioru danych usuniemy 10% wartości z kolumny \"it_seller_rating\".Nastęnie spróbujemy algorytmem  Nearest neighbors imputation uzupełnić te braki danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(420020/10) #Wielkość Danych\n",
    "nan = np.nan\n",
    "data2 = copy.deepcopy(data)\n",
    "data3 = copy.deepcopy(data)\n",
    "data2 = data2.head(n)\n",
    "data2 = data2[['price', 'it_quantity']]\n",
    "row = data3['it_seller_rating']\n",
    "row_comp = copy.deepcopy(row)\n",
    "\n",
    "for i in range(int(n/10)):\n",
    "    row.loc[i * 10] = nan\n",
    "data2['it_seller_rating'] = row # Nasze dane z brakami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         50177\n",
      "1         12428\n",
      "2          7389\n",
      "3         15006\n",
      "4         32975\n",
      "          ...  \n",
      "420015      176\n",
      "420016    34851\n",
      "420017      983\n",
      "420018      163\n",
      "420019      265\n",
      "Name: it_seller_rating, Length: 420020, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(row_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = imputer.fit_transform(data2)\n",
    "data2 = pd.DataFrame({'it_seller_rating': data2[:,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       it_seller_rating\n",
      "0               50483.0\n",
      "1               12428.0\n",
      "2                7389.0\n",
      "3               15006.0\n",
      "4               32975.0\n",
      "...                 ...\n",
      "41997            9306.0\n",
      "41998            9306.0\n",
      "41999           15108.0\n",
      "42000           58407.0\n",
      "42001           10233.0\n",
      "\n",
      "[42002 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = []\n",
    "y_predicted = []\n",
    "for i in range(int(n/10)):\n",
    "    y_actual.append(row_comp.at[i*10])\n",
    "    y_predicted.append(data2.at[i*10,'it_seller_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = sqrt(mean_squared_error(y_actual,y_predicted ))\n",
    "scores = [0]*10\n",
    "scores[9] = rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for mk in range(9):\n",
    "    data2 = copy.deepcopy(data)\n",
    "    data3 = copy.deepcopy(data)\n",
    "    data2 = data2.head(n)\n",
    "    data2 = data2[['price', 'it_quantity']]\n",
    "    row = data3['it_seller_rating']\n",
    "    row_comp = copy.deepcopy(row)\n",
    "\n",
    "    for i in range(int(n / 10)):\n",
    "        row.loc[i * 10 + mk + 1] = nan\n",
    "\n",
    "    data2['it_seller_rating'] = row  # Nasze dane z brakami\n",
    "    \n",
    "    \n",
    "    data2 = imputer.fit_transform(data2)\n",
    "    data2 = pd.DataFrame({'it_seller_rating': data2[:, 2]})\n",
    "    \n",
    "    y_actual = []\n",
    "    y_predicted = []\n",
    "    for i in range(int(n / 10)):\n",
    "        y_actual.append(row_comp.at[i * 10 + mk + 1])\n",
    "        y_predicted.append(data2.at[i * 10 + mk + 1, 'it_seller_rating'])\n",
    "    \n",
    "    rms = sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "    scores[mk] = rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35834.21492842072, 35575.730588735096, 34316.31153674452, 35906.63482101632, 35868.03616627869, 35019.97981222818, 34834.8771533338, 34159.92270550581, 34236.60675212314, 35935.9751910578]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla róznych braków danych wartości średnie mają zbliżone wartośći"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = copy.deepcopy(data)\n",
    "data3 = copy.deepcopy(data)\n",
    "data4 = copy.deepcopy(data)\n",
    "data2 = data2.head(n)\n",
    "data2 = data2[['price']]\n",
    "row_sel = data3['it_seller_rating']\n",
    "row_qua = data4['it_quantity']\n",
    "row_comp_sel = copy.deepcopy(row_sel)\n",
    "row_comp_qua = copy.deepcopy(row_qua)\n",
    "for i in range(int(n/10)):\n",
    "    row_sel.loc[i * 10] = nan\n",
    "    row_qua.loc[i * 10 + 4] = nan\n",
    "data2['it_seller_rating'] = row_sel # Nasze dane z brakami\n",
    "data2['it_quantity'] = row_qua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        price  it_seller_rating  it_quantity\n",
      "0       59.99               NaN        997.0\n",
      "1        4.90           12428.0       9288.0\n",
      "2      109.90            7389.0        895.0\n",
      "3       18.50           15006.0        971.0\n",
      "4       19.90           32975.0          NaN\n",
      "...       ...               ...          ...\n",
      "41997    2.40            9306.0       1515.0\n",
      "41998    2.40            9306.0       1515.0\n",
      "41999    2.00           15108.0          0.0\n",
      "42000   31.90           58407.0         10.0\n",
      "42001  429.99           10233.0         66.0\n",
      "\n",
      "[42002 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = imputer.fit_transform(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame({'it_seller_rating': data2[:,1],'it_quantity': data2[:,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       it_seller_rating  it_quantity\n",
      "0                1543.5        997.0\n",
      "1               12428.0       9288.0\n",
      "2                7389.0        895.0\n",
      "3               15006.0        971.0\n",
      "4               32975.0         11.5\n",
      "...                 ...          ...\n",
      "41997            9306.0       1515.0\n",
      "41998            9306.0       1515.0\n",
      "41999           15108.0          0.0\n",
      "42000           58407.0         10.0\n",
      "42001           10233.0         66.0\n",
      "\n",
      "[42002 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_actual_sel = []\n",
    "    y_predicted_sel = []\n",
    "    y_actual_qua = []\n",
    "    y_predicted_qua = []\n",
    "    for i in range(int(n / 10)):\n",
    "        y_actual_sel.append(row_comp_sel.at[i * 10])\n",
    "        y_predicted_sel.append(data2.at[i * 10, 'it_seller_rating'])\n",
    "        y_actual_qua.append(row_comp_sel.at[i * 10])\n",
    "        y_predicted_qua.append(data2.at[i * 10, 'it_quantity'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_sel = sqrt(mean_squared_error(y_actual_sel,y_predicted_sel))\n",
    "rms_qua = sqrt(mean_squared_error(y_actual_qua,y_predicted_qua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41497.25540014306 44432.06442848078\n"
     ]
    }
   ],
   "source": [
    "print(rms_sel,rms_qua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać że wraz ze zmniejszeniem danych które mamy zwiększyła się niedokładność naszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
